{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad58648c-e104-4e07-90e8-e48cd4cd69a3",
   "metadata": {},
   "source": [
    "# Other Tools: Gensim\n",
    "\n",
    "```yaml\n",
    "Course:   DS 5001\n",
    "Module:   08a Visualization\n",
    "Topic:    Other Tools\n",
    "Author:   R.C. Alvarado\n",
    "Date:     23 March 2023\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfab29a-7c46-4399-a6e1-85adf5fcdfa8",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e642a-d9ec-454c-9361-35c43d954c99",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5de37fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7ac46a-ef6c-40af-a09e-f69bcf16957f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_topics = 100\n",
    "data_dir = f\"{data_home}/newsgroups/20news-18828\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977d51d-d407-49ae-994d-0a8e54f26eda",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1df1207-4306-48d3-901a-9c27bfdb23a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "from collections import defaultdict\n",
    "import plotly_express as px\n",
    "from glob import glob\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57187001-26c6-4191-b611-fab2520dc426",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c43bd04-efc6-45a8-b236-febfd0986d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    data = []\n",
    "    for d in glob(data_dir+\"/*\"):\n",
    "        label = d.split(\"/\")[-1]\n",
    "        print(label)\n",
    "        for f in glob(d+\"/*\"):\n",
    "            fid = f.split(\"/\")[-1]\n",
    "            flines = open(f, 'r', encoding=\"latin-1\").read().split(\"\\n\")\n",
    "            from_line = ':'.join(flines[0].split(':')[1:])\n",
    "            subj_line = ':'.join(flines[1].split(':')[1:])\n",
    "            data.append((fid, label, from_line, subj_line, ' '.join(flines[2:])))\n",
    "    LIB = pd.DataFrame(data, columns=['doc_id','doc_label','doc_from', 'doc_subj', 'doc_content'])\n",
    "    LIB.doc_id = LIB.doc_id.astype('int')\n",
    "    LIB = LIB.set_index(['doc_label','doc_id'])\n",
    "    return LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5566f2d3-bb14-46db-b11a-85d94b90307b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIB = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db55c77-064c-4cd5-b1e7-17b3d8d0af37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>doc_from</th>\n",
       "      <th>doc_subj</th>\n",
       "      <th>doc_content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_label</th>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_from, doc_subj, doc_content]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3deb9928-fbcf-4965-b3fd-b14b5831b057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIB.to_csv(f\"{output_dir}/newsgroups-LIB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5147a-2a8e-4211-9a9e-89df4859b551",
   "metadata": {},
   "source": [
    "## Pre-Process the Gensim Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebea83-2816-4800-8f6d-dd2967da3507",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead7fd7-bf4f-4be5-a50e-910a477e2996",
   "metadata": {},
   "source": [
    "We create a set of frequent words. Of course, we can grab a premade list from somewhere else, such as NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3cfffe-8872-4a37-91fb-c4a9a38400ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in is i that it you this be on are'.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b7c53-668b-443b-a10e-fb37f240fd57",
   "metadata": {},
   "source": [
    "### Corpus\n",
    "\n",
    "We loop through the list of docs and do some parsing and shaping on the fly. \n",
    "\n",
    "Again, we could do better with tools from NLTK.\n",
    "\n",
    "Here we lowercase each document, split it by white space, remove non-alphanumeric characters, and filter out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a904f355-28c7-44e1-ba48-2158cbf23a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = [[re.sub(r\"[\\W_]+\", \"\", word) for word in document.lower().split() if word not in stoplist]\n",
    "         for document in LIB.doc_content.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63c541-e8cd-4219-adf6-e6175811db8f",
   "metadata": {},
   "source": [
    "### Term Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ed526-6355-4b75-9709-6c316b03a8a0",
   "metadata": {},
   "source": [
    "We count word frequencies in order to filter out low-frequency words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf079eba-27c4-45a0-8a08-4f0b321b2b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2baa7b-105c-4139-a31c-e18665778a3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtered Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67869539-86b7-4583-81e9-0a15b94f8fb0",
   "metadata": {},
   "source": [
    "We filter by frequency, removing words that appear once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ddaf665-7451-4f96-a6a8-b69469b7ada1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_corpus = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4ce97-5973-4296-8c4b-7f6979e9a32e",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d6538-589b-4f48-b3e4-2002d8bd9d7d",
   "metadata": {},
   "source": [
    "We create a \"dictionary,\" aka a vocabulary, which associates a term string with a numeric identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7dc0085-735f-44aa-9ed2-876a6cde7ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(filtered_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d58e1-0865-4f42-9516-ca4e19a97072",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a1aa3-a84e-44ae-be41-1b34ccb5dfa9",
   "metadata": {},
   "source": [
    "We create the BOW corpus from the text using the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ec1cf1-d75c-4720-8975-afcea18f147e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in filtered_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6480b9b-fea4-47a6-9a89-fe7f9147e701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bow_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f515319-e8e5-4001-a55a-2935a99fb98e",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d1b09-ddb3-4e2f-b4ca-3cd8f0bdc9f8",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67c365c-7f06-4d9a-8a5d-1d9e94966a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d52bc4-bf6a-4f18-8d1e-9b1543891bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tfidf[bow_corpus[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdc0d9-c954-458b-8596-cb50f79d3891",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e19f8531-2562-40c4-b71c-a432b06eefeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot compute LDA over an empty collection (no terms)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(bow_corpus, id2word\u001b[38;5;241m=\u001b[39mdictionary, num_topics\u001b[38;5;241m=\u001b[39mnum_topics)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\ldamodel.py:448\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_terms \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot compute LDA over an empty collection (no terms)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(distributed)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_topics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(num_topics)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot compute LDA over an empty collection (no terms)"
     ]
    }
   ],
   "source": [
    "model = models.LdaModel(bow_corpus, id2word=dictionary, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c23f8-9e5d-4fc2-b1d7-243c9aa0c547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = models.HdpModel(bow_corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f073b5-6bec-48c5-9eec-c9efdef52af5",
   "metadata": {},
   "source": [
    "## Convert to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d600dfd-c7be-4cf9-ab22-45ca8cbf5737",
   "metadata": {},
   "source": [
    "### VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85bfba-eb20-4874-b0b3-c69b2419a823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB = pd.DataFrame([(k, v) for k, v in dictionary.token2id.items()], columns=['term_str','term_id']) #.set_index('term_id')\n",
    "VOCAB['n'] = VOCAB.term_str.map(lambda x: frequency[x])\n",
    "VOCAB = VOCAB.set_index('term_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13a883-23c8-4865-9f1d-865a9b4cbd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f537a9-13d4-4d20-af22-bcd7b6ae171d",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ac710-0c9c-4080-ad50-e161e1c5f323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_data = []\n",
    "for doc_id, doc in enumerate(bow_corpus):\n",
    "    for term in tfidf[doc]:\n",
    "        tfidf_data.append((doc_id, term[0], term[1]))\n",
    "TFIDF = pd.DataFrame(tfidf_data, columns=['doc_id','term_id', 'tfidf']).set_index(['doc_id','term_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a07f1-4f67-45e1-a106-99f92e187d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TFIDF.tfidf.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2eb752-39f8-4773-bcff-032442f8c56e",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d09778-3bbb-43ef-8bce-3a1fafc100b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bow_data = []\n",
    "for i, doc in enumerate(bow_corpus):\n",
    "    for term in doc:\n",
    "        bow_data.append((i, term[0], term[1]))\n",
    "BOW = pd.DataFrame(bow_data, columns=['doc_id','term_id', 'n']).set_index(['doc_id','term_id'])     \n",
    "DTM = BOW.n.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e023be2-98d1-475a-a8ab-e30466be026a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099c30f-a714-42df-b4fd-2655f88dda75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DTM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4b4c1-2acc-4935-9bf7-81f7844b9770",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b4f59-0720-4229-b448-5693876b02e8",
   "metadata": {},
   "source": [
    "#### PHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337929a4-eecf-4c7f-b06a-d48f8302cf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PHI = pd.DataFrame(model.get_topics()).T\n",
    "PHI.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672560e-71c6-4534-8c5d-95877c014bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PHI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62f4e5-a1ea-4902-9d11-313fc143fdd7",
   "metadata": {},
   "source": [
    "#### THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1fc70-36e0-4a77-9f1e-96ae85db5db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_data = []\n",
    "for doc_id, doc_bow in enumerate(bow_corpus):\n",
    "    for topic in model.get_document_topics(doc_bow):\n",
    "        theta_data.append((doc_id, topic[0], topic[1]))\n",
    "THETA = pd.DataFrame(theta_data, columns=['doc_id', 'topic_id', 'topic_weight']).set_index(['doc_id','topic_id']).unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ab0cc-251f-4b2e-ae6d-5b2b54d330c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THETA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff45ae-09c0-483a-b0e6-dfe7ea219bc9",
   "metadata": {},
   "source": [
    "#### TOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f86fd-dc5d-48da-86d4-40ae5102ce4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_data = []\n",
    "for t in range(num_topics):\n",
    "    for term_rank, term in enumerate(model.get_topic_terms(t)):\n",
    "        term_id = term[0]\n",
    "        topic_data.append((t, term_rank, dictionary.id2token[term_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2632cd-227e-4f28-a415-c5c331caa23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC = pd.DataFrame(topic_data, columns=['topic_id', 'term_rank', 'term_str'])\\\n",
    "    .set_index(['topic_id','term_rank']).term_str.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbeb14-7c05-40a0-bb78-1d11a98436f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOPIC.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
