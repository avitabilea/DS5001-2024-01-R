{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c7b170-ee8d-494e-96b6-2ceb547c8301",
   "metadata": {},
   "source": [
    "# Entropy Examples\n",
    "\n",
    "```yaml\n",
    "Course:  DS 5001\n",
    "Module:  03 Lab\n",
    "Topic:   Homework\n",
    "Author:  Andrew Avitabile\n",
    "Date:    02 February 2024\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6e2dd-0628-4d7b-bfdf-8b8d5d566cd2",
   "metadata": {},
   "source": [
    "## Set up and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb740b4e-8ff6-4a4d-9341-798a1d46d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd824e8-b7d5-4fcf-ab93-d64e07d133d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Configuration\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fa838c-92a6-4309-b872-6660f8ace13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Textparser\n",
    "textparser = %run \"../lib/textparser.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae27fbb-55cc-4aed-b43b-8e6485206686",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05ab7dd-4693-4254-93b6-5e1f0b4482c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define text_file as Frankenstien\n",
    "text_file = f\"{data_home}/gutenberg/pg42324.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a62b23-a988-4ecc-b322-5ca2144b53f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use local library to clean data\n",
    "import sys\n",
    "local_lib = config['DEFAULT']['local_lib']\n",
    "sys.path.append(local_lib) \n",
    "from textimporter import TextImporter\n",
    "from textparser import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a1f5cc-de28-49ac-9f45-d71636dec14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define OHCO\n",
    "OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b0acc7-c490-4a59-a45e-ede9229daad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define patterns to split text into component parts of OHCO\n",
    "clip_pats = [\n",
    "    r\"M\\. W\\. S\\.\",\n",
    "    r\"THE END.\"\n",
    "]\n",
    "chap_pat = r\"^\\s*(?:chapter|letter|preface)\\s+[IVXLCDMivxlcdm]+\"\n",
    "sent_pat = r'[.?!;:]+'\n",
    "token_pat = r\"[\\s',-]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e6bffb-7773-40d7-ad28-2165de1756f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/pg42324.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*(?:chapter|letter|preface)\\s+[IVXLCDMivxlcdm]+\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by delimitter [.?!;:]+\n",
      "Parsing OHCO level 3 token_num by delimitter [\\s',-]+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<textimporter.TextImporter at 0x2cf53190650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize using TextImporter.py\n",
    "my_text = TextImporter(src_file=text_file, ohco_pats=[('chap', chap_pat, 'm')], clip_pats=clip_pats)\n",
    "my_text.import_source()\n",
    "my_text.parse_tokens()\n",
    "my_text.extract_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c1958d-397c-4494-8c09-b64545ec5555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>_To</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Saville</td>\n",
       "      <td>saville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>lost</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     token_str  term_str\n",
       "chap_num para_num sent_num token_num                    \n",
       "1        0        0        0               _To        to\n",
       "                           1               Mrs       mrs\n",
       "                  1        1           Saville   saville\n",
       "                           2           England   england\n",
       "                  2        0                 _          \n",
       "...                                        ...       ...\n",
       "28       82       1        10             lost      lost\n",
       "                           11               in        in\n",
       "                           12         darkness  darkness\n",
       "                           13              and       and\n",
       "                           14         distance  distance\n",
       "\n",
       "[75721 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract tokens and rename the axisdf.query()\n",
    "TOKEN = my_text.TOKENS\n",
    "TOKEN = TOKEN.rename_axis(index={'chap_id': 'chap_num'})\n",
    "TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add237f1-e2f9-4ba4-8388-4bd345e4f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the vocaublary\n",
    "VOCAB = my_text.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5352b0aa-8c12-4949-bf84-855a5e180757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "      <th>modified_term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4197</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>18.041696</td>\n",
       "      <td>4.173263</td>\n",
       "      <td>0.231312</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2976</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>25.443884</td>\n",
       "      <td>4.669247</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>26.550140</td>\n",
       "      <td>4.730648</td>\n",
       "      <td>0.178178</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2647</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>28.606347</td>\n",
       "      <td>4.838263</td>\n",
       "      <td>0.169133</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>36.040457</td>\n",
       "      <td>5.171545</td>\n",
       "      <td>0.143493</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overweigh</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>overweigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledge</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>pledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salvation</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>salvation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timorous</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>timorous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>thinks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  n_chars         p             s          i         h  \\\n",
       "term_str                                                                \n",
       "the        4197        3  0.055427     18.041696   4.173263  0.231312   \n",
       "and        2976        3  0.039302     25.443884   4.669247  0.183512   \n",
       "i          2852        1  0.037665     26.550140   4.730648  0.178178   \n",
       "of         2647        2  0.034957     28.606347   4.838263  0.169133   \n",
       "to         2101        2  0.027747     36.040457   5.171545  0.143493   \n",
       "...         ...      ...       ...           ...        ...       ...   \n",
       "overweigh     1        9  0.000013  75721.000000  16.208406  0.000214   \n",
       "pledge        1        6  0.000013  75721.000000  16.208406  0.000214   \n",
       "salvation     1        9  0.000013  75721.000000  16.208406  0.000214   \n",
       "timorous      1        8  0.000013  75721.000000  16.208406  0.000214   \n",
       "thinks        1        6  0.000013  75721.000000  16.208406  0.000214   \n",
       "\n",
       "          modified_term_str  \n",
       "term_str                     \n",
       "the                     the  \n",
       "and                     and  \n",
       "i                         i  \n",
       "of                       of  \n",
       "to                       to  \n",
       "...                     ...  \n",
       "overweigh         overweigh  \n",
       "pledge               pledge  \n",
       "salvation         salvation  \n",
       "timorous           timorous  \n",
       "thinks               thinks  \n",
       "\n",
       "[6965 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove tokens only appear once and are fewer than 3 characters\n",
    "VOCAB['modified_term_str'] = VOCAB.index\n",
    "VOCAB.loc[(VOCAB.n == 1) & (VOCAB.n_chars < 3), 'modified_term_str'] = \"<UNK>\"\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ac364f-4ca9-4134-ac3d-aade2b697090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>modified_term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>39</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2d</td>\n",
       "      <td>2d</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>16</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>3</th>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>ne</td>\n",
       "      <td>ne</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>45</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <td>du</td>\n",
       "      <td>du</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     token_str term_str modified_term_str\n",
       "chap_num para_num sent_num token_num                                     \n",
       "3        7        1        1                 W        w             <UNK>\n",
       "28       39       0        1                2d       2d             <UNK>\n",
       "10       16       4        2                 n        n             <UNK>\n",
       "14       3        8        5                ne       ne             <UNK>\n",
       "25       45       5        7                du       du             <UNK>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make this same change in the tokenized dataset\n",
    "TOKEN['modified_term_str'] = TOKEN.term_str.map(VOCAB.modified_term_str)\n",
    "TOKEN[TOKEN.modified_term_str == '<UNK>'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c79c39-3662-4e53-abf0-c4a1556938d6",
   "metadata": {},
   "source": [
    "## Make NGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462c66da-b4ae-47f4-8f0c-e9809be5074f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w0', 'w1', 'w2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NGRAM PREP\n",
    "ngrams = 3\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "widx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26caf13-be35-4a9f-bb90-61315d62b400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_to_padded(token, grouper=['sent_num'], term_str='term_str'):\n",
    "    ohco = token.index.names # We preserve these since they get lost in the shuffle\n",
    "    padded = token.groupby(grouper)\\\n",
    "        .apply(lambda x: '<s> ' + ' '.join(x[term_str]) + ' </s>')\\\n",
    "        .apply(lambda x: pd.Series(x.split()))\\\n",
    "        .stack().to_frame('term_str')\n",
    "    padded.index.names = ohco\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac940196-76d0-48e3-be58-d1c8f53fa22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDED = token_to_padded(TOKEN, grouper=OHCO[:3], term_str='modified_term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa6c08d-f1cb-4f8d-8590-bc8356bc841a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     term_str\n",
       "chap_num para_num sent_num token_num         \n",
       "1        0        0        0              <s>\n",
       "                           1               to\n",
       "                           2              mrs\n",
       "                           3             </s>\n",
       "                  1        0              <s>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PADDED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c75596-1353-49d2-b1fb-bc51a40dac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_to_ngrams(padded, grouper=['sent_num'], n=2):\n",
    "    \n",
    "    ohco = padded.index.names\n",
    "    ngrams = padded.groupby(grouper).apply(lambda x: pd.concat([x.shift(0-i) for i in range(n)], axis=1)).reset_index(drop=True)\n",
    "    ngrams.index = padded.index\n",
    "    ngrams.columns = widx\n",
    "\n",
    "    # ngrams = pd.concat([padded.shift(0-i) for i in range(n)], axis=1)\n",
    "    # ngrams.index.name = 'ngram_num'\n",
    "    # ngrams.columns = widx\n",
    "    # ngrams = ngrams.fillna('<EOF>')\n",
    "    \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f163134-62bf-4d33-8d35-5649b67965b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NGRAMS = padded_to_ngrams(PADDED, OHCO[:3], ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcab819f-60fb-4e43-8050-9e1c61acbb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>to</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>mrs</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>saville</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            w0        w1        w2\n",
       "chap_num para_num sent_num token_num                              \n",
       "1        0        0        0               <s>        to       mrs\n",
       "                           1                to       mrs      </s>\n",
       "                           2               mrs      </s>      None\n",
       "                           3              </s>      None      None\n",
       "                  1        0               <s>   saville   england\n",
       "...                                        ...       ...       ...\n",
       "28       82       1        11               in  darkness       and\n",
       "                           12         darkness       and  distance\n",
       "                           13              and  distance      </s>\n",
       "                           14         distance      </s>      None\n",
       "                           15             </s>      None      None\n",
       "\n",
       "[85654 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NGRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84f19e-bdb4-4c5c-8a16-afd6afd80ccd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c104f8-1367-4fdb-8f5a-c881f54527b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ngrams_to_models(ngrams):\n",
    "    global widx\n",
    "    n = len(ngrams.columns)\n",
    "    model = [None for i in range(n)]\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            model[i] = ngrams.value_counts('w0').to_frame('n')\n",
    "            model[i]['p'] = model[i].n / model[i].n.sum()\n",
    "            model[i]['i'] = np.log2(1/model[i].p)\n",
    "        else:\n",
    "            model[i] = ngrams.value_counts(widx[:i+1]).to_frame('n')    \n",
    "            model[i]['cp'] = model[i].n / model[i-1].n\n",
    "            model[i]['i'] = np.log2(1/model[i].cp)\n",
    "        model[i] = model[i].sort_index()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d13366-c54b-4892-a044-a6ffb3777244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = ngrams_to_models(NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab073ae7-b94a-422a-ba7d-883f6c8f7610",
   "metadata": {},
   "source": [
    "## Define additional funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96d0f2e-51d9-4ad8-bce7-0c7eaf4c789a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_to_token(sent_list, file=True):\n",
    "    \n",
    "    # Convert list of sentences to dataframe\n",
    "    if file:\n",
    "        S = pd.read_csv(\"test_sentences_HW.txt\", header=None, names=['sent_str'])\n",
    "    else:\n",
    "        S = pd.DataFrame(sent_list, columns=['sent_str'])\n",
    "    S.index.name = 'sent_num'\n",
    "    \n",
    "    # Convert dataframe of sentences to TOKEN with normalized terms\n",
    "    K = S.sent_str.apply(lambda x: pd.Series(x.split())).stack().to_frame('token_str')\n",
    "    K['term_str'] = K.token_str.str.replace(r\"[\\W_]+\", \"\", regex=True).str.lower()\n",
    "    K.index.names = ['sent_num', 'token_num']\n",
    "    \n",
    "    return S, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1216264-e39b-4363-a8c5-1988f7624722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, ngrams, sents):\n",
    "    \n",
    "    global widx\n",
    "    \n",
    "    assert len(model) == len(ngrams.columns)\n",
    "    \n",
    "    n = len(model)\n",
    "    ohco = ngrams.index.names\n",
    "    \n",
    "    R = []\n",
    "    for i in range(n):\n",
    "        T = ngrams.merge(M[i], on=widx[:i+1], how='left')\n",
    "        T.index = ngrams.index\n",
    "        T = T.reset_index().set_index(ohco + widx).i #.to_frame(f\"i{i}\")\n",
    "        \n",
    "        # This how we handle unseen combos\n",
    "        T[T.isna()] = T.max()\n",
    "        R.append(T.to_frame(f\"i{i}\"))\n",
    "                \n",
    "    return pd.concat(R, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b5e9ce6-a7a5-40d3-a7b9-fdd1493ded86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(results, test_sents, n=3):\n",
    "    for i in range(n):\n",
    "        test_sents[f\"pp{i}\"] = np.exp2(results.groupby('sent_num')[f\"i{i}\"].mean())\n",
    "    return test_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f36b72ef-9e7e-472d-b4ba-69afe3f268f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(M, n=250):\n",
    "    \n",
    "    if len(M) < 3:\n",
    "        raise ValueError(\"Must have trigram model generated.\")\n",
    "    \n",
    "    # Start list of words\n",
    "    first_word = M[1].loc['<s>'].sample(weights='cp').index[0]\n",
    "    \n",
    "    words = ['<s>', first_word]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        bg = tuple(words[-2:])\n",
    "\n",
    "        # Try trigram model\n",
    "        try:\n",
    "            next_word = M[2].loc[bg].sample(weights='cp').index[0]\n",
    "\n",
    "        # If not found in model, back off ...\n",
    "        except KeyError as e1:\n",
    "            try:\n",
    "                # Get the last word in the bigram\n",
    "                ug = bg[1]\n",
    "                next_word = M[1].loc[ug].sample(weights='cp').index[0]\n",
    "            \n",
    "            except KeyError as e2:\n",
    "                next_word = M[0].sample(weights='p').index[0]\n",
    "                \n",
    "        words.append(next_word)\n",
    "    \n",
    "    \n",
    "    text = ' '.join(words[2:])\n",
    "    print('\\n\\n'.join([str(i+1) + ' ' + line.replace('<s>','').strip().upper() for i, line in enumerate(text.split('</s>'))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88140df-9867-472b-8523-6a4916ab8d2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 1\n",
    "List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the df.query() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1533331-526c-4377-92c8-dc2da6254671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>3</th>\n",
       "      <th>17</th>\n",
       "      <th>25</th>\n",
       "      <td>miserable</td>\n",
       "      <td>monster</td>\n",
       "      <td>whom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>abhorred</td>\n",
       "      <td>monster</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>25</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <td>detestable</td>\n",
       "      <td>monster</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>28</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>hideous</td>\n",
       "      <td>monster</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">28</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>5</th>\n",
       "      <td>hellish</td>\n",
       "      <td>monster</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <td>gigantic</td>\n",
       "      <td>monster</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              w0       w1     w2\n",
       "chap_num para_num sent_num token_num                            \n",
       "9        3        17       25          miserable  monster   whom\n",
       "14       8        0        1            abhorred  monster   </s>\n",
       "19       25       4        23         detestable  monster   </s>\n",
       "20       28       0        1             hideous  monster   </s>\n",
       "28       4        9        5             hellish  monster  drink\n",
       "         17       6        2            gigantic  monster   they"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = NGRAMS.query('(w1 == \"monster\") & (w0 != \"an\") & (w0 != \"a\") & (w0 != \"the\") & (w0 != \"this\") & (w0 != \"that\") & (w0 != \"<s>\")')\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073640c-8d5c-4cc9-b33c-f1415652a6cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 2\n",
    "List the following sentences in ascending order of bigram perplexity according to the language model generated from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a33bdc64-65b7-41a6-86fb-2e21248ae8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>pp0</th>\n",
       "      <th>pp1</th>\n",
       "      <th>pp2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The monster is on the ice.</td>\n",
       "      <td>116.146797</td>\n",
       "      <td>80.632951</td>\n",
       "      <td>68.983256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He never knew the love of a family.</td>\n",
       "      <td>170.855904</td>\n",
       "      <td>136.870520</td>\n",
       "      <td>64.734928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have never seen the aurora borealis.</td>\n",
       "      <td>340.954187</td>\n",
       "      <td>138.718691</td>\n",
       "      <td>81.279212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers are happy things.</td>\n",
       "      <td>587.205060</td>\n",
       "      <td>533.982028</td>\n",
       "      <td>182.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sent_str         pp0         pp1  \\\n",
       "sent_num                                                                   \n",
       "0                     The monster is on the ice.  116.146797   80.632951   \n",
       "3            He never knew the love of a family.  170.855904  136.870520   \n",
       "2         I have never seen the aurora borealis.  340.954187  138.718691   \n",
       "1                      Flowers are happy things.  587.205060  533.982028   \n",
       "\n",
       "                 pp2  \n",
       "sent_num              \n",
       "0          68.983256  \n",
       "3          64.734928  \n",
       "2          81.279212  \n",
       "1         182.500000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SENTS, TEST_TOKENS = sentence_to_token(\"test_sentences_HW.txt\")\n",
    "TEST_PADDED = token_to_padded(TEST_TOKENS)\n",
    "TEST_NGRAMS = padded_to_ngrams(TEST_PADDED, 'sent_num', ngrams)\n",
    "R = test_model(M,TEST_NGRAMS, TEST_SENTS)\n",
    "PP = compute_perplexity(R, TEST_SENTS)\n",
    "PP.sort_values(by='pp1', ascending=True, inplace=True)\n",
    "PP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1f18b-6c02-4784-b282-a1c9ed530325",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 3\n",
    "Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists:\n",
    "\n",
    "['he','she'] to select the indices.\n",
    "\n",
    "['said','heard'] to select the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b617de6-cdf6-46d8-99eb-dbeebc373cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">cp</th>\n",
       "      <th colspan=\"2\" halign=\"left\">i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w1</th>\n",
       "      <th>heard</th>\n",
       "      <th>said</th>\n",
       "      <th>heard</th>\n",
       "      <th>said</th>\n",
       "      <th>heard</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>6.928370</td>\n",
       "      <td>4.857981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>6.409391</td>\n",
       "      <td>6.409391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n             cp                   i          \n",
       "w1  heard said     heard      said     heard      said\n",
       "w0                                                    \n",
       "he      5   21  0.008210  0.034483  6.928370  4.857981\n",
       "she     3    3  0.011765  0.011765  6.409391  6.409391"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter bigram model to W0 W1 == he/she and W1 == said/heard\n",
    "filtered_df = M[1].query('((w0 == \"he\") | (w0 == \"she\")) & ((w1 == \"said\") | (w1 == \"heard\"))')\n",
    "filtered_df.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271065c-a65a-483a-8184-b997aa99e346",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Generate 20 sentences using the generate_text() function. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f64f1fb-ad5d-49c6-9c97-960a4b409f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 EXCLAIMED\n",
      "\n",
      "2 SUBJECT\n",
      "\n",
      "3 WAS THE WORK OF INCONCEIVABLE DIFFICULTY AND LABOUR\n",
      "\n",
      "4 THE MAJESTIC OAKS THE QUANTITY OF GAME AND THE SPRINGING OF A GUIDE\n",
      "\n",
      "5 AND CONQUERED AND WHO ARE SO EMINENTLY DESERVING\n",
      "\n",
      "6 WHICH HAD BECOME\n",
      "\n",
      "7 AND COMFORTLESS SKY\n",
      "\n",
      "8 TO RESTORE IT TO MY TOO KEEN SENSATIONS\n",
      "\n",
      "9 THE DECAYING FRAME OF THE INHERITANCE OF ELIZABETH OR MY FATHER ENTERED THE HUT\n",
      "\n",
      "10 DURING MY FIRST RESOLUTION WAS TO CONVEY ME AWAY AND WE RESOLVED TO REMAIN IN A SCENE OF THE GRAVE WORMS CRAWLING IN THE HEAVENS AND GAVE YOU AN IDEA STRUCK ME AS A DEFORMED AND HORRIBLE AS MYSELF\n",
      "\n",
      "11 THOUSAND FEARS\n",
      "\n",
      "12 FROM JUSTINE COULD DISSIPATE\n",
      "\n",
      "13 SECRET\n",
      "\n",
      "14 THAN A ROCK WHOSE HIGH SIDES WERE CONTINUALLY BEATEN UPON BY THE MODERN MASTERS PROMISE VERY LITTLE AND CONVERSED IN BROKEN ACCENTS WHILST I COMPREHENDED AND COULD SUBSIST UPON COARSER DIET\n",
      "\n",
      "15 JUST RETRIBUTION BURNING WITHIN MY HANDS\n",
      "\n",
      "16 OF MY FRIENDS AND MY FATHER S CONSENT TO GO AND HEAR THAT NO ASSISTANCE COULD SAVE ANY PART OF EACH DAY AT NOON WHEN I HEARD THE SILVER HAIR AND BENEVOLENT MIND\n",
      "\n",
      "17 THE FIEND WOULD FOLLOW ME\n",
      "\n",
      "18 THAT IS ALSO MY DEAREST FRIEND YOU MUST BEGIN YOUR STUDIES ENTIRELY ANEW\n",
      "\n",
      "19 THE RAIN PATTERED DISMALLY AGAINST THE PANES HAD BEEN CHOSEN BY THE LIGHT OF A HUMAN BEING IN PERFECTION OUGHT ALWAYS TO PRESERVE MY LIFE HAD HITHERTO INHABITED TO SEEK ONE WHO WOULD GAIN HIS FEE\n",
      "\n",
      "20 \n"
     ]
    }
   ],
   "source": [
    "generate_text(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8af8e-6113-4265-88d1-f99b2ef82fe6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 5\n",
    "Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the .mle feature as $p$ in computing $H = \\sum p(ng)log_2(1/p(ng))$. \n",
    "\n",
    "Hint: Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ its maximum entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a1ed98a-ed4a-42e6-aace-8bbba8d9872b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate probability\n",
    "M[1]['p'] = M[1].n /  M[1].n.sum()\n",
    "M[2]['p'] = M[2].n /  M[2].n.sum()\n",
    "\n",
    "#Calculate infomration\n",
    "M[1]['log2p_1_over_p'] = np.log2(1/M[1].p)\n",
    "M[2]['log2p_1_over_p'] = np.log2(1/M[2].p)\n",
    "\n",
    "#Calculate N\n",
    "M[1]['N'] = len(M[0].index)**2\n",
    "M[2]['N'] = len(M[0].index)**3\n",
    "\n",
    "#Log2(1/N)\n",
    "M[1]['log2_1_over_N'] = np.log2(1/M[1].n.sum())\n",
    "M[2]['log2_1_over_N'] = np.log2(1/M[2].n.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fefefad-3f32-4d95-8f14-041a88682624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.130511267844236"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(M[1].p*M[1].log2p_1_over_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93c1406f-fdd2-4c80-956c-d931f120c0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.258369986141371"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1/M[1].n.sum()*M[1].log2_1_over_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20501ff2-eaa2-4397-b13e-5b8851fa10cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate entropy (H) and max entropy (H_max)\n",
    "M[1]['H'] = sum(M[1].p*M[1].log2p_1_over_p)\n",
    "M[1]['H_max'] = sum(1/M[1].n.sum()*M[1].log2_1_over_N)\n",
    "M[2]['H'] = sum(M[2].p*M[2].log2p_1_over_p)\n",
    "M[2]['H_max'] = sum(1/M[2].n.sum()*M[2].log2_1_over_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ecf2dcb-f39f-4af3-9294-abf8a76a0bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate R\n",
    "R_1 = 1-(M[1]['H']/M[1]['H_max'])\n",
    "R_2 = 1-(M[2]['H']/M[2]['H_max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0bb76-806a-45de-80fc-c29247aac26b",
   "metadata": {},
   "source": [
    "Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7538b585-f2a4-4871-a019-b8d10d1aa116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.71105331])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(R_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb3bf31c-c662-497d-968d-264951311adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.13406816])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(R_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d72114-cb3a-442f-9d76-c6bd00157c96",
   "metadata": {},
   "source": [
    "As shown above, $R$ decreases as the n-gram increases in length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
