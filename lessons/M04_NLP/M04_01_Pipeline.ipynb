{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and the Pipeline\n",
    "\n",
    "```yaml\n",
    "Course:   DS 5001\n",
    "Module:   04 Lab\n",
    "Topic:    NLP and the Pipeline\n",
    "Author:   R.C. Alvarado\n",
    "Date:     5 February 2023\n",
    "```\n",
    "\n",
    "**Purpose**:  We import a collection of texts and convert to F2. Then we annotate the collection to create an F3-level model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "To install plotly_express with conda:\n",
    "\n",
    "```bash\n",
    "conda install plotly::plotly_express \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_files = f'{data_home}/gutenberg/austen-melville-set'\n",
    "data_prefix = 'austen-melville'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(local_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textparser import TextParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "Since Project Gutenberg texts vary widely in their markup, we define our chunking patterns by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF\",\n",
    "    r\"\\*\\*\\*\\s*END OF\"\n",
    "]\n",
    "\n",
    "# All are 'chap'and 'm'\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "ohco_pat_list = [\n",
    "    (158,   rf\"^\\s*CHAPTER\\s+{roman}\\s*$\"),\n",
    "    (946,   rf\"^\\s*{roman}\\s*$\"),\n",
    "    (1212,  rf\"^\\s*LETTER .* to .*$\"),\n",
    "    (141,   rf\"^CHAPTER\\s+{roman}$\"),\n",
    "    (121,   rf\"^CHAPTER\\s+\\d+$\"),\n",
    "    (105,   rf\"^Chapter\\s+\\d+$\"),\n",
    "    (1342,  rf\"^Chapter\\s+\\d+$\"),\n",
    "    (161,   rf\"^CHAPTER\\s+\\d+$\"),    \n",
    "    (15422, rf\"^\\s*CHAPTER\\s+{roman}\\.\"),\n",
    "    (13720, rf\"^\\s*CHAPTER\\s+{roman}\\s*$\"),\n",
    "    (13721, rf\"^\\s*CHAPTER\\s+{roman}\\s*$\"),\n",
    "    (2701,  rf\"^(?:ETYMOLOGY|EXTRACTS|CHAPTER)\"),\n",
    "    (4045,  rf\"^\\s*CHAPTER\\s+{roman}\\.\\s*$\"),\n",
    "    (34970, rf\"^\\s*{roman}\\.\\s*$\"),\n",
    "    (8118,  rf\"^\\s*{roman}\\. .*$\"),\n",
    "    (21816, rf\"^CHAPTER\\s+{roman}\\.?$\"),\n",
    "    (15859, rf\"^\\s*[A-Z,;-]+\\.\\s*$\"),\n",
    "    (1900,  rf\"^CHAPTER \"),\n",
    "    (10712, rf\"^CHAPTER\\s+{roman}\\.\\s*$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register\n",
    "\n",
    "We get each file and add to a library `LIB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    # Splitting file path by \"\\\\\" for Windows paths or \"/\" for Unix-like paths\n",
    "    parts = source_file_path.split('\\\\') if '\\\\' in source_file_path else source_file_path.split('/')\n",
    "    \n",
    "    # Extracting book ID from the last part of the file name\n",
    "    book_id = int(parts[-1].split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    \n",
    "    # Extracting book title from the second-to-last part of the file name\n",
    "    book_title = parts[-1].split('-')[0].replace('_', ' ')\n",
    "    \n",
    "    # Appending book data tuple to book_data list\n",
    "    book_data.append((book_id, source_file_path, book_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE PERSUASION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE NORTHANGER ABBEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE MANSFIELD PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE EMMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE SENSE AND SENSIBILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE LADY SUSAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE LOVE AND FREINDSHIP SIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN JANE PRIDE AND PREJUDICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN TYPEE A ROMANCE OF THE SOUTH SEAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN MOBY DICK OR THE WHALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN OMOO ADVENTURES IN THE SOUTH SEAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN WHITE JACKET OR THE WORLD ON A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN MARDI AND A VOYAGE THITHER VOL I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN MARDI AND A VOYAGE THITHER VOL II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN ISRAEL POTTER HIS FIFTY YEARS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN THE PIAZZA TALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN THE CONFIDENCE MAN HIS MASQUERADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34970</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE HERMAN PIERRE OR THE AMBIGUITIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "105      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "121      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "141      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "158      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "161      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "946      C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "1212     C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "1342     C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "1900     C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "2701     C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "4045     C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "10712    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "13720    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "13721    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "15422    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "15859    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "21816    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "34970    C:/Users/Andre/OneDrive - University of Virgin...   \n",
       "\n",
       "                                                 raw_title  \n",
       "book_id                                                     \n",
       "105                                 AUSTEN JANE PERSUASION  \n",
       "121                           AUSTEN JANE NORTHANGER ABBEY  \n",
       "141                             AUSTEN JANE MANSFIELD PARK  \n",
       "158                                       AUSTEN JANE EMMA  \n",
       "161                      AUSTEN JANE SENSE AND SENSIBILITY  \n",
       "946                                 AUSTEN JANE LADY SUSAN  \n",
       "1212                  AUSTEN JANE LOVE AND FREINDSHIP SIC   \n",
       "1342                       AUSTEN JANE PRIDE AND PREJUDICE  \n",
       "1900     MELVILLE HERMAN TYPEE A ROMANCE OF THE SOUTH SEAS  \n",
       "2701                MELVILLE HERMAN MOBY DICK OR THE WHALE  \n",
       "4045     MELVILLE HERMAN OMOO ADVENTURES IN THE SOUTH SEAS  \n",
       "10712    MELVILLE HERMAN WHITE JACKET OR THE WORLD ON A...  \n",
       "13720     MELVILLE HERMAN MARDI AND A VOYAGE THITHER VOL I  \n",
       "13721    MELVILLE HERMAN MARDI AND A VOYAGE THITHER VOL II  \n",
       "15422    MELVILLE HERMAN ISRAEL POTTER HIS FIFTY YEARS ...  \n",
       "15859                     MELVILLE HERMAN THE PIAZZA TALES  \n",
       "21816    MELVILLE HERMAN THE CONFIDENCE MAN HIS MASQUERADE  \n",
       "34970            MELVILLE HERMAN PIERRE OR THE AMBIGUITIES  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10712"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "book_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    LIB['author'] = LIB.raw_title.apply(lambda x: ', '.join(x.split()[:2]))\n",
    "    LIB['title'] = LIB.raw_title.apply(lambda x: ' '.join(x.split()[2:]))\n",
    "    LIB = LIB.drop('raw_title', axis=1)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PERSUASION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>NORTHANGER ABBEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>MANSFIELD PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>EMMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>SENSE AND SENSIBILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>LADY SUSAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>LOVE AND FREINDSHIP SIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PRIDE AND PREJUDICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>TYPEE A ROMANCE OF THE SOUTH SEAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MOBY DICK OR THE WHALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>OMOO ADVENTURES IN THE SOUTH SEAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>WHITE JACKET OR THE WORLD ON A MAN OF WAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MARDI AND A VOYAGE THITHER VOL I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MARDI AND A VOYAGE THITHER VOL II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>ISRAEL POTTER HIS FIFTY YEARS OF EXILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>THE PIAZZA TALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>THE CONFIDENCE MAN HIS MASQUERADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34970</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>PIERRE OR THE AMBIGUITIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path            author  \\\n",
       "book_id                                                                        \n",
       "105      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "121      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "141      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "158      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "161      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "946      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1212     C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1342     C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1900     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "2701     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "4045     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "10712    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "13720    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "13721    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "15422    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "15859    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "21816    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "34970    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "\n",
       "                                             title  \n",
       "book_id                                             \n",
       "105                                     PERSUASION  \n",
       "121                               NORTHANGER ABBEY  \n",
       "141                                 MANSFIELD PARK  \n",
       "158                                           EMMA  \n",
       "161                          SENSE AND SENSIBILITY  \n",
       "946                                     LADY SUSAN  \n",
       "1212                       LOVE AND FREINDSHIP SIC  \n",
       "1342                           PRIDE AND PREJUDICE  \n",
       "1900             TYPEE A ROMANCE OF THE SOUTH SEAS  \n",
       "2701                        MOBY DICK OR THE WHALE  \n",
       "4045             OMOO ADVENTURES IN THE SOUTH SEAS  \n",
       "10712    WHITE JACKET OR THE WORLD ON A MAN OF WAR  \n",
       "13720             MARDI AND A VOYAGE THITHER VOL I  \n",
       "13721            MARDI AND A VOYAGE THITHER VOL II  \n",
       "15422       ISRAEL POTTER HIS FIFTY YEARS OF EXILE  \n",
       "15859                             THE PIAZZA TALES  \n",
       "21816            THE CONFIDENCE MAN HIS MASQUERADE  \n",
       "34970                    PIERRE OR THE AMBIGUITIES  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Chapter regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PERSUASION</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>NORTHANGER ABBEY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>MANSFIELD PARK</td>\n",
       "      <td>^CHAPTER\\s+[IVXLCM]+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>EMMA</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>SENSE AND SENSIBILITY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>LADY SUSAN</td>\n",
       "      <td>^\\s*[IVXLCM]+\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>LOVE AND FREINDSHIP SIC</td>\n",
       "      <td>^\\s*LETTER .* to .*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PRIDE AND PREJUDICE</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>TYPEE A ROMANCE OF THE SOUTH SEAS</td>\n",
       "      <td>^CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MOBY DICK OR THE WHALE</td>\n",
       "      <td>^(?:ETYMOLOGY|EXTRACTS|CHAPTER)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>OMOO ADVENTURES IN THE SOUTH SEAS</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>WHITE JACKET OR THE WORLD ON A MAN OF WAR</td>\n",
       "      <td>^CHAPTER\\s+[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MARDI AND A VOYAGE THITHER VOL I</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>MARDI AND A VOYAGE THITHER VOL II</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>ISRAEL POTTER HIS FIFTY YEARS OF EXILE</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>THE PIAZZA TALES</td>\n",
       "      <td>^\\s*[A-Z,;-]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>THE CONFIDENCE MAN HIS MASQUERADE</td>\n",
       "      <td>^CHAPTER\\s+[IVXLCM]+\\.?$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34970</th>\n",
       "      <td>C:/Users/Andre/OneDrive - University of Virgin...</td>\n",
       "      <td>MELVILLE, HERMAN</td>\n",
       "      <td>PIERRE OR THE AMBIGUITIES</td>\n",
       "      <td>^\\s*[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path            author  \\\n",
       "book_id                                                                        \n",
       "105      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "121      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "141      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "158      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "161      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "946      C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1212     C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1342     C:/Users/Andre/OneDrive - University of Virgin...      AUSTEN, JANE   \n",
       "1900     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "2701     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "4045     C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "10712    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "13720    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "13721    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "15422    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "15859    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "21816    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "34970    C:/Users/Andre/OneDrive - University of Virgin...  MELVILLE, HERMAN   \n",
       "\n",
       "                                             title  \\\n",
       "book_id                                              \n",
       "105                                     PERSUASION   \n",
       "121                               NORTHANGER ABBEY   \n",
       "141                                 MANSFIELD PARK   \n",
       "158                                           EMMA   \n",
       "161                          SENSE AND SENSIBILITY   \n",
       "946                                     LADY SUSAN   \n",
       "1212                       LOVE AND FREINDSHIP SIC   \n",
       "1342                           PRIDE AND PREJUDICE   \n",
       "1900             TYPEE A ROMANCE OF THE SOUTH SEAS   \n",
       "2701                        MOBY DICK OR THE WHALE   \n",
       "4045             OMOO ADVENTURES IN THE SOUTH SEAS   \n",
       "10712    WHITE JACKET OR THE WORLD ON A MAN OF WAR   \n",
       "13720             MARDI AND A VOYAGE THITHER VOL I   \n",
       "13721            MARDI AND A VOYAGE THITHER VOL II   \n",
       "15422       ISRAEL POTTER HIS FIFTY YEARS OF EXILE   \n",
       "15859                             THE PIAZZA TALES   \n",
       "21816            THE CONFIDENCE MAN HIS MASQUERADE   \n",
       "34970                    PIERRE OR THE AMBIGUITIES   \n",
       "\n",
       "                              chap_regex  \n",
       "book_id                                   \n",
       "105                      ^Chapter\\s+\\d+$  \n",
       "121                      ^CHAPTER\\s+\\d+$  \n",
       "141                ^CHAPTER\\s+[IVXLCM]+$  \n",
       "158          ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$  \n",
       "161                      ^CHAPTER\\s+\\d+$  \n",
       "946                    ^\\s*[IVXLCM]+\\s*$  \n",
       "1212                ^\\s*LETTER .* to .*$  \n",
       "1342                     ^Chapter\\s+\\d+$  \n",
       "1900                           ^CHAPTER   \n",
       "2701     ^(?:ETYMOLOGY|EXTRACTS|CHAPTER)  \n",
       "4045       ^\\s*CHAPTER\\s+[IVXLCM]+\\.\\s*$  \n",
       "10712         ^CHAPTER\\s+[IVXLCM]+\\.\\s*$  \n",
       "13720        ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$  \n",
       "13721        ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$  \n",
       "15422          ^\\s*CHAPTER\\s+[IVXLCM]+\\.  \n",
       "15859                ^\\s*[A-Z,;-]+\\.\\s*$  \n",
       "21816           ^CHAPTER\\s+[IVXLCM]+\\.?$  \n",
       "34970                ^\\s*[IVXLCM]+\\.\\s*$  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Corpus\n",
    "\n",
    "We tokenize each book and add each `TOKENS` table to a list to be concatenated into a single `CORPUS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_collection(LIB):\n",
    "\n",
    "    clip_pats = [\n",
    "        r\"\\*\\*\\*\\s*START OF\",\n",
    "        r\"\\*\\*\\*\\s*END OF\"\n",
    "    ]\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats, use_nltk=True)\n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        # Parse\n",
    "        text.import_source().parse_tokens();\n",
    "\n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^\\\\s*[A-Z,;-]+\\\\.\\\\s*$'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[15859].chap_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 105 PERSUASION\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_PERSUASION-pg105.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^Chapter\\s+\\d+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 121 NORTHANGER ABBEY\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_NORTHANGER_ABBEY-pg121.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^CHAPTER\\s+\\d+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 141 MANSFIELD PARK\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_MANSFIELD_PARK-pg141.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^CHAPTER\\s+[IVXLCM]+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 158 EMMA\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_EMMA-pg158.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 161 SENSE AND SENSIBILITY\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_SENSE_AND_SENSIBILITY-pg161.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^CHAPTER\\s+\\d+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 946 LADY SUSAN\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_LADY_SUSAN-pg946.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*[IVXLCM]+\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1212 LOVE AND FREINDSHIP SIC\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_LOVE_AND_FREINDSHIP_SIC_-pg1212.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*LETTER .* to .*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1342 PRIDE AND PREJUDICE\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\AUSTEN_JANE_PRIDE_AND_PREJUDICE-pg1342.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^Chapter\\s+\\d+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1900 TYPEE A ROMANCE OF THE SOUTH SEAS\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\MELVILLE_HERMAN_TYPEE_A_ROMANCE_OF_THE_SOUTH_SEAS-pg1900.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^CHAPTER \n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 2701 MOBY DICK OR THE WHALE\n",
      "Importing  C:/Users/Andre/OneDrive - University of Virginia/Course Materials/Spring 2024/DS5001/data/gutenberg/austen-melville-set\\MELVILLE_HERMAN_MOBY_DICK_OR_THE_WHALE-pg2701.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^(?:ETYMOLOGY|EXTRACTS|CHAPTER)\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract some features for `LIB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['book_len'] = CORPUS.groupby('book_id').term_str.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.sort_values('book_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_id','chap_id']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(LIB, 'n_chaps', 'book_len', \n",
    "           color='author', text='n_chaps', size='book_len', \n",
    "           hover_name='title', width=800, height=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.groupby('author')[['book_len', 'n_chaps']].agg(('mean','sum'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exract VOCAB\n",
    "\n",
    "Extract a vocabulary from the CORPUS as a whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Anomalies\n",
    "\n",
    "NLTK's POS tagger is not perfect -- note the classification of punctuation as nouns, verbs, etc. We remove these from our corups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS[CORPUS.term_str == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS[CORPUS.term_str == ''].token_str.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CORPUS = CORPUS[CORPUS.term_str != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CORPUS['pos_group'] = CORPUS.pos.str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH",
    "tags": []
   },
   "source": [
    "# Annotate VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Max POS\n",
    "\n",
    "Get the most frequently associated part-of-speech category for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute POS ambiguity\n",
    "\n",
    "How many POS categories are associated with each word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['n_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos_group.apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['n_pos'] = CORPUS[['term_str','pos']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos'] = CORPUS[['term_str','pos']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos.apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "US7EfWK_06FS"
   },
   "source": [
    "## Add Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDCfFuN80_rX"
   },
   "source": [
    "We use NLTK's built in stopword list for English. Note that we can add and subtract from this list, or just create our own list and keep it in our data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG-5qYDR1YC2"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1925
    },
    "colab_type": "code",
    "id": "8vtGY9V82scz",
    "outputId": "e7ef30c7-3a05-4acf-e2cc-9154f589bd91"
   },
   "outputs": [],
   "source": [
    "# sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVJUOP9l2AS7"
   },
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "QXcA9xyY4JF_",
    "outputId": "340d1dab-1901-4eeb-b9d8-a269eba90dea"
   },
   "outputs": [],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Stopword Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = VOCAB.groupby('stop').n_chars.mean()\n",
    "b = VOCAB.groupby('stop').n_pos.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([a,b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.groupby('n_chars').n_pos.mean()\\\n",
    "    .sort_index().plot.bar(rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious that stopwords would have such variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB[VOCAB.stop == True].sort_values('n_pos', ascending=False)[['n_pos','cat_pos']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, let's compare stopword usage across authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CORPUS.merge(LIB.reset_index()[['book_id','author']], on='book_id')\\\n",
    "    .merge(VOCAB.reset_index()[['term_str', 'stop']], on='term_str')\\\n",
    "    .groupby(['author','stop']).agg('sum', numeric_only=True).unstack()\n",
    "X.columns = X.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X.T / X.T.sum()).T.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH"
   },
   "source": [
    "## Add Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE_YGklKXSYn"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.apply(lambda x: stemmer2.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.apply(lambda x: stemmer3.stem(x.name), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [],
   "source": [
    "VOCAB[VOCAB.stem_porter != VOCAB.stem_snowball]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f'{output_dir}/{data_prefix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIB.to_csv(f'{out_path}-LIB.csv')\n",
    "VOCAB.to_csv(f'{out_path}-VOCAB.csv')\n",
    "CORPUS.to_csv(f'{out_path}-CORPUS.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_Annotations.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
